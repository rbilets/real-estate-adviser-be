{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb42e88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle,WA\n",
      "seattle,wa\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "location = \"Seattle,WA\"\n",
    "print(location)\n",
    "\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e42c6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle\n",
      "WA\n"
     ]
    }
   ],
   "source": [
    "city, state = location.split(\",\")[0].capitalize(), location.split(\",\")[1].upper()\n",
    "\n",
    "\n",
    "\n",
    "print(city)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c5c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:2015-01-01 End:2015-04-01 Count:1308\n",
      "Start:2015-04-02 End:2015-06-30 Count:2327\n",
      "Start:2015-07-01 End:2015-09-28 Count:2254\n",
      "Start:2015-09-29 End:2015-12-27 Count:1833\n",
      "Start:2015-12-28 End:2016-03-26 Count:1352\n",
      "Start:2016-03-27 End:2016-06-24 Count:2508\n",
      "Start:2016-06-25 End:2016-09-22 Count:2532\n",
      "Start:2016-09-23 End:2016-12-21 Count:2134\n",
      "Start:2016-12-22 End:2017-03-21 Count:1555\n",
      "Start:2017-03-22 End:2017-06-19 Count:2379\n",
      "Start:2017-06-20 End:2017-09-17 Count:2521\n",
      "Start:2017-09-18 End:2017-12-16 Count:2441\n",
      "Start:2017-12-17 End:2018-03-16 Count:1641\n",
      "Start:2018-03-17 End:2018-06-14 Count:2373\n",
      "Start:2018-06-15 End:2018-09-12 Count:2375\n",
      "Start:2018-09-13 End:2018-12-11 Count:1973\n",
      "Start:2018-12-12 End:2019-03-11 Count:1549\n",
      "Start:2019-03-12 End:2019-06-09 Error:'INDUSTRIAL' is not a valid PropertyType\n",
      "Start:2019-06-10 End:2019-09-07 Count:2763\n",
      "Start:2019-09-08 End:2019-12-06 Count:2490\n",
      "Start:2019-12-07 End:2020-03-05 Count:2027\n",
      "Start:2020-03-06 End:2020-06-03 Count:2277\n",
      "Start:2020-06-04 End:2020-09-01 Count:3416\n",
      "Start:2020-09-02 End:2020-11-30 Count:3664\n",
      "Start:2020-12-01 End:2021-02-28 Count:2635\n",
      "Start:2021-03-01 End:2021-05-29 Count:4274\n",
      "Start:2021-05-30 End:2021-08-27 Count:4399\n",
      "Start:2021-08-28 End:2021-11-25 Count:3766\n",
      "Start:2021-11-26 End:2022-02-23 Count:2559\n",
      "Start:2022-02-24 End:2022-05-24 Count:3950\n",
      "Start:2022-05-25 End:2022-08-22 Count:3397\n",
      "Start:2022-08-23 End:2022-11-20 Count:2435\n",
      "Start:2022-11-21 End:2023-02-18 Count:1588\n",
      "Start:2023-02-19 End:2023-05-19 Count:2551\n",
      "Start:2023-05-20 End:2023-08-17 Count:2514\n",
      "Start:2023-08-18 End:2023-11-15 Count:2042\n",
      "Start:2023-11-16 End:2024-02-13 Count:1370\n",
      "Start:2024-02-14 End:2024-05-13 Count:1692\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90864 entries, 0 to 90863\n",
      "Data columns (total 29 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   property_url    90864 non-null  object \n",
      " 1   mls             61317 non-null  object \n",
      " 2   mls_id          61317 non-null  object \n",
      " 3   status          90864 non-null  object \n",
      " 4   style           90814 non-null  object \n",
      " 5   street          90864 non-null  object \n",
      " 6   unit            29301 non-null  object \n",
      " 7   city            90864 non-null  object \n",
      " 8   state           90864 non-null  object \n",
      " 9   zip_code        90864 non-null  object \n",
      " 10  beds            86514 non-null  object \n",
      " 11  full_baths      85291 non-null  object \n",
      " 12  half_baths      24351 non-null  object \n",
      " 13  sqft            89070 non-null  object \n",
      " 14  year_built      88375 non-null  object \n",
      " 15  days_on_mls     40994 non-null  object \n",
      " 16  list_price      61317 non-null  object \n",
      " 17  list_date       61317 non-null  object \n",
      " 18  sold_price      90864 non-null  float64\n",
      " 19  last_sold_date  90864 non-null  object \n",
      " 20  lot_sqft        76907 non-null  object \n",
      " 21  price_per_sqft  88946 non-null  object \n",
      " 22  latitude        89447 non-null  float64\n",
      " 23  longitude       89447 non-null  float64\n",
      " 24  stories         47777 non-null  object \n",
      " 25  hoa_fee         35450 non-null  object \n",
      " 26  parking_garage  20382 non-null  object \n",
      " 27  primary_photo   90864 non-null  object \n",
      " 28  alt_photos      90864 non-null  object \n",
      "dtypes: float64(3), object(26)\n",
      "memory usage: 20.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = scrape_historical_sales(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4da887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['distance_to_downtown'] = dataset.apply(lambda row: self.calc_lat_lon_dist(row['latitude'], row['longitude'], self.downtown_lat, self.downtown_lon), axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['baths'] = dataset.apply(lambda row: self.calc_baths_num(row[\"full_baths\"], row[\"half_baths\"]), axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['sqft'] = dataset.apply(lambda row: 0.0 if pd.isna(row[\"sqft\"]) and row[\"style\"] == \"LAND\" else row[\"sqft\"], axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['style'] = dataset.apply(lambda row: \"OTHER\" if pd.isna(row[\"style\"]) else row[\"style\"], axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['lot_sqft'] = dataset.apply(lambda row: 0.0 if pd.isna(row[\"lot_sqft\"]) else row[\"lot_sqft\"], axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['hoa_fee'] = dataset.apply(lambda row: 0.0 if pd.isna(row[\"hoa_fee\"]) else row[\"hoa_fee\"], axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['stories'] = dataset.apply(lambda row: 0.0 if pd.isna(row[\"stories\"]) else row[\"stories\"], axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['beds'] = dataset.apply(lambda row: 0.0 if pd.isna(row[\"beds\"]) else row[\"beds\"], axis=1)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['sold_year'] = pd.to_datetime(dataset['last_sold_date']).apply(lambda x: x.year)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.dropna(subset=[\"year_built\", \"sqft\", \"distance_to_downtown\", \"parking_garage\"], inplace=True)\n",
      "C:\\Users\\roman.bilets\\AppData\\Local\\Temp\\ipykernel_105688\\72580958.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['age'] = dataset.apply(lambda row: row[\"sold_year\"] - row[\"year_built\"], axis=1)\n"
     ]
    }
   ],
   "source": [
    "dataset = PropertyDatasetProcessor(df, city).clean_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3349cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with the score: 0.7991304167587265\n"
     ]
    }
   ],
   "source": [
    "model = train_model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04de47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_model = pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be57558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size:  60522111\n"
     ]
    }
   ],
   "source": [
    "print(\"Model size: \", len(serialized_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f07a7e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'etag': '\"0x8DC6176454EAE69\"',\n",
       " 'last_modified': datetime.datetime(2024, 4, 20, 20, 12, 57, tzinfo=datetime.timezone.utc),\n",
       " 'content_md5': None,\n",
       " 'content_crc64': bytearray(b'h\\xc5\\x12~\\xbc\\xa5\\xaa8'),\n",
       " 'client_request_id': '611b448f-ff52-11ee-98d6-f0b61e5d13e8',\n",
       " 'request_id': '0bc97858-501e-0065-465f-932b52000000',\n",
       " 'version': '2023-11-03',\n",
       " 'version_id': None,\n",
       " 'date': datetime.datetime(2024, 4, 20, 20, 12, 57, tzinfo=datetime.timezone.utc),\n",
       " 'request_server_encrypted': True,\n",
       " 'encryption_key_sha256': None,\n",
       " 'encryption_scope': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04d1a275",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "The specified blob or block content is invalid.\nRequestId:fcdc58ae-301e-004c-345d-931526000000\nTime:2024-04-20T20:03:12.3019470Z\nErrorCode:InvalidBlobOrBlock\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>InvalidBlobOrBlock</Code><Message>The specified blob or block content is invalid.\nRequestId:fcdc58ae-301e-004c-345d-931526000000\nTime:2024-04-20T20:03:12.3019470Z</Message></Error>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m     block_ids\u001b[38;5;241m.\u001b[39mappend(base64_block_id)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Commit the blocks to create the final blob\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mblob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit_block_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m uploaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\diploma\\Repos\\real-estate-scraper\\.venv\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32m~\\Desktop\\diploma\\Repos\\real-estate-scraper\\.venv\\lib\\site-packages\\azure\\storage\\blob\\_blob_client.py:2904\u001b[0m, in \u001b[0;36mBlobClient.commit_block_list\u001b[1;34m(self, block_list, content_settings, metadata, **kwargs)\u001b[0m\n\u001b[0;32m   2902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mblock_blob\u001b[38;5;241m.\u001b[39mcommit_block_list(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2903\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m-> 2904\u001b[0m     \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\diploma\\Repos\\real-estate-scraper\\.venv\\lib\\site-packages\\azure\\storage\\blob\\_shared\\response_handlers.py:184\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[1;34m(storage_error)\u001b[0m\n\u001b[0;32m    181\u001b[0m error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (error\u001b[38;5;241m.\u001b[39mmessage,)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise error from None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: The specified blob or block content is invalid.\nRequestId:fcdc58ae-301e-004c-345d-931526000000\nTime:2024-04-20T20:03:12.3019470Z\nErrorCode:InvalidBlobOrBlock\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>InvalidBlobOrBlock</Code><Message>The specified blob or block content is invalid.\nRequestId:fcdc58ae-301e-004c-345d-931526000000\nTime:2024-04-20T20:03:12.3019470Z</Message></Error>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import base64\n",
    "import pickle\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "\n",
    "# Assuming 'config' is defined elsewhere in your project\n",
    "\n",
    "\n",
    "# Initialize the BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Create a unique blob name\n",
    "\n",
    "blob_client = container_client.get_blob_client(blob=blob_name)\n",
    "\n",
    "# Serialize the model\n",
    "serialized_model = pickle.dumps(model)\n",
    "\n",
    "# Function to divide the model into chunks\n",
    "def get_chunks(data, chunk_size=4 * 1024 * 1024):  # Default to 4MB chunks\n",
    "    index = 0\n",
    "    while index < len(data):\n",
    "        yield data[index:index + chunk_size]\n",
    "        index += chunk_size\n",
    "\n",
    "# List to store block ids\n",
    "block_ids = []\n",
    "\n",
    "# Upload the chunks\n",
    "for i, chunk in enumerate(get_chunks(serialized_model)):\n",
    "    block_id = str(uuid.uuid4()).encode('utf-8')  # Generate a unique block id\n",
    "    base64_block_id = base64.b64encode(block_id).decode('utf-8')\n",
    "    blob_client.stage_block(block_id=base64_block_id, data=chunk, length=len(chunk))\n",
    "    block_ids.append(base64_block_id)\n",
    "\n",
    "# Commit the blocks to create the final blob\n",
    "blob_client.commit_block_list([{'id': id} for id in block_ids])\n",
    "\n",
    "print(f\"{blob_name} uploaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bf38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = os.path.join(os.getcwd(), 'historical_data')\n",
    "\n",
    "# dataframes = []\n",
    "\n",
    "\n",
    "# for file_name in os.listdir(folder_path):\n",
    "#     if file_name.endswith('.csv'):\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "#         df = pd.read_csv(file_path)\n",
    "#         dataframes.append(df)\n",
    "\n",
    "# print(len(dataframes))\n",
    "# combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3407e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rf_model.predict(X_test)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print(f'Test RMSE: {rmse}')\n",
    "\n",
    "# rf_score = rf_model.score(X_test,y_test)\n",
    "# expl_rf = explained_variance_score(y_pred, y_test)\n",
    "\n",
    "\n",
    "# models_score =pd.DataFrame({'Model':['Random forest Regression'],\n",
    "#                             'Score':[rf_score],\n",
    "#                             'Explained Variance Score':[expl_rf]\n",
    "#                            })\n",
    "# models_score.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09866a89",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a1b0d-4302-464e-8428-0047e7d10145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "# sns.plotting_context('notebook',font_scale=1.2)\n",
    "# g = sns.pairplot(dataset, hue='beds',height=2)\n",
    "# g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bd8c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.jointplot(x='zip_code',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='beds',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='sqft',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='year_built',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='last_sold_date',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='lot_sqft',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='stories',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='hoa_fee',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='parking_garage',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='distance_to_downtown',y='sold_price',data=dataset,kind='reg',height=4)\n",
    "# sns.jointplot(x='baths',y='sold_price',data=dataset,kind='reg',height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,10))\n",
    "# sns.heatmap(dataset.corr(),annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
